{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OYhNQecnbyhU"
      },
      "outputs": [],
      "source": [
        "import torch                                  # Main PyTorch Library\n",
        "import torchvision                            # Tools connected to applying ML to Vision problems\n",
        "import torchvision.transforms as transforms   # Tools for transforming the shape or form of data\n",
        "import torchvision.datasets as datasets       # Vision (Image) Datasets\n",
        "import matplotlib.pyplot as plt               # Useful if we want to plot anything\n",
        "import numpy as np                            # Numerical matrix/array calculation support\n",
        "import torch.nn as nn                         # Specific pytorch functionality useful for neural networks\n",
        "import torch.optim as optim                   # PyTorch optimizers (let it handle the gradient updates so you don't have to)\n",
        "import random                                 # Just in case we need some random numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R2rzhpz-c3dq"
      },
      "outputs": [],
      "source": [
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform = transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST\n",
        "- **Input**: $x \\in \\mathbb{R}^{28 \\times 28}$\n",
        "- **Output**: $y \\in \\{0, 1, 2, 3, 4, 5, 6, 7, 8, 9\\}$\n",
        "- **Model**: $F(\\vec{x})=\\text{softmax}(A\\vec{x} + b)$\n",
        "  - $A: (10\\times784) \\cdot \\vec{x}: (864 \\times 1) + \\vec{b}: (10 \\times 1)$\n",
        "\n"
      ],
      "metadata": {
        "id": "IYElCa04B_Es"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfq1YSpTcP9I",
        "outputId": "eae4bae5-98a3-43e1-adf4-aaa3e6e94702"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "trainset.data.shape # Shows image, pixel, pixel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9KdEskkdBum",
        "outputId": "12fb036b-3493-4d23-c973-8d09fe261dd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
              "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
              "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
              "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
              "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
              "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
              "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
              "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
              "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
              "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
              "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
              "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
              "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
              "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
              "       dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "trainset.data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "f9qo6rhZdIy7",
        "outputId": "9393fb6e-9230-4193-f656-fd0e760806d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def imshow(img):\n",
        "  img = img / 256 # Scale everything to be between 0 and 1\n",
        "  plt.imshow( img ) # Generate the image\n",
        "  plt.show() # Show the image\n",
        "\n",
        "imshow( trainset.data[0] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeNKpNV1dOBe",
        "outputId": "72dad405-bffa-4fdb-8669-834d3adbc130"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "trainset.targets[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lxPNGSoDdSIX"
      },
      "outputs": [],
      "source": [
        "x_train = (trainset.data / 256) - 0.5 # This rescales the images so that every pixel value is now between -0.5 and 0.5, which is generally just at a nicer scale than 0 to 256, numerically.\n",
        "y_train = trainset.targets\n",
        "\n",
        "# Scaling things to be close to 0 -> more numerically stable for calculations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSZinMFWC4Nw",
        "outputId": "639ae1d6-d6a7-48f6-9ca6-fc596d39c9ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hZMu4OzAdi_p"
      },
      "outputs": [],
      "source": [
        "x_train = torch.nn.Flatten()( x_train ) # puts all pixels in one line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRJ-a3FPdsTc",
        "outputId": "4302f791-f39e-4ec6-9a60-d54025b13a41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "x_train.shape # 60000 vectors (pictures) of length 784 -> better for math we will do"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tt14Owei781",
        "outputId": "0fd838cd-fd8a-48f7-e6d8-f0b6f1b5d8e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "\n",
        "Using softmax: $F(x)=\\text{softmax}(Ax + b)$"
      ],
      "metadata": {
        "id": "quvDRcEcDUwE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dw-YD0kYdgZu"
      },
      "outputs": [],
      "source": [
        "A = torch.nn.Parameter( torch.randn(10, 784), requires_grad = True ) # tells PyTorch to keep track of all the information to calculate gradients\n",
        "b = torch.nn.Parameter( torch.randn(10,1), requires_grad = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPJVkOvAEocp",
        "outputId": "c0ad84a9-fdcc-4803-d243-563ac704a52c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-1.7810,  0.5015,  0.6334,  ..., -1.1527, -0.3246, -0.9180],\n",
              "        [-0.7085, -1.1851,  0.1450,  ..., -0.1880,  1.8444,  0.2751],\n",
              "        [-1.1511,  0.1793, -0.3236,  ..., -0.7637,  0.1113, -0.3546],\n",
              "        ...,\n",
              "        [-0.4152, -0.6384, -0.6692,  ..., -1.0911, -2.0136,  0.4380],\n",
              "        [ 0.6467,  1.5456, -1.5975,  ...,  1.3514, -2.4219,  1.1258],\n",
              "        [ 0.5953, -0.8522, -0.0906,  ...,  2.0625, -0.9246, -1.0234]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cannot just say Ax+b since dimensions don't match\n",
        "* A: 10 rows x 784 cols\n",
        "* x_train: 60000 rows x 784 cols\n",
        "* But, x_train transpose: 784 rows x 60000 cols\n",
        "\n",
        "Matrix multiplication will now work. Cannot use \"*\" since that is just the dot product. Need \"matmul\" or \"@\"."
      ],
      "metadata": {
        "id": "Iv5bt6oxEsqW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1n-wLM3d6E-",
        "outputId": "f80fb60e-0598-42f9-d817-22638c4b13fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 60000])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "torch.matmul(A, x_train.t()).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we want in the end is 60000 x 10 -> for each of the 60000 data points, want 10 real values"
      ],
      "metadata": {
        "id": "oTrqkGa0FfnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bias vector is 10 x 1"
      ],
      "metadata": {
        "id": "Z_e0BgA1Fw7b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "C0eydJGQfOLM"
      },
      "outputs": [],
      "source": [
        "linear_mapping = torch.matmul(A, x_train.t()) + b"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of broadcasting:\n",
        "\n",
        "* A $\\times$ x_train: 10 x 60000\n",
        "* b: 10 x 1"
      ],
      "metadata": {
        "id": "H0osKYquGJcG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXFz0wEIfzFx",
        "outputId": "88201ec8-2518-412c-e84f-562f4eec34c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 60000])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "linear_mapping.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qu4m-N5Nf0bc"
      },
      "outputs": [],
      "source": [
        "linear_mapping = linear_mapping.t()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15vWKZV3gVrK",
        "outputId": "2d748057-6ad2-4380-b260-f9685490fe59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "linear_mapping.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJID71k-gW5i",
        "outputId": "b1eea587-6543-4f9b-ec7b-7dc390eb8c0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ -8.1428,   3.5295,  -9.8017,  -0.7199, -16.1750, -26.2776,  -2.3536,\n",
              "         18.1751,  12.8549,  16.5923], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "linear_mapping[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logits: real value that we plug into softmax to get probabilities"
      ],
      "metadata": {
        "id": "EmHWS9wwGfWr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yazGbDm8grXv"
      },
      "outputs": [],
      "source": [
        "logits = linear_mapping.t()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JcPs9HmvgtXj"
      },
      "outputs": [],
      "source": [
        "probabilities = torch.nn.Softmax( dim = 1 )( logits )\n",
        "\n",
        "# logits is 60000x10 matrix\n",
        "# probabilities = softmax(logits) would do softmax on every single value -> results in 60000x10 matrix, sum of all entries is 1\n",
        "# we want each row to be a set of separate probability values so we do it only on dim=1 -> softmax across the rows"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epIfxXxsHOD_",
        "outputId": "d244ef26-4832-4eec-a65d-27e31f1d439c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 60000])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouIuX5CMgyKI",
        "outputId": "bd7da889-a18f-4cbb-88b9-32f9bbf8bfe0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.1617e-12, 8.7327e-14, 5.7248e-18,  ..., 1.2201e-13, 4.4103e-13,\n",
              "        3.2964e-18], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "probabilities[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above:\n",
        "\n",
        "tensor([1.2508e-08, 9.6900e-11, 9.9968e-01, 1.1587e-15, 1.0502e-12, 9.1993e-08,\n",
        "        7.3484e-13, 6.9942e-13, 3.0872e-04, 8.9547e-06],\n",
        "       grad_fn=<SelectBackward0>)\n",
        "\n",
        "9.9968e-01 shows that it is very confident that the number is a 3 (largest number), when we know it should be 5. There is no reason for it to perform well since it has not been optimized yet."
      ],
      "metadata": {
        "id": "PekrK0d1Hys9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8sJbJ8Mgz4o",
        "outputId": "ca0c2810-aaab-409c-eb9f-a1d4cf4f31cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0000, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "torch.sum( probabilities[ 0 ] )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "yebPDzMYIHCW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z6Em7qzkfw4",
        "outputId": "d11fcfd8-169e-4c5b-d5d4-ff6a10ec6485"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP5LH0OomO0F",
        "outputId": "51e81320-41c3-4347-f730-790db0586891"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "np.arange(0,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "NbMO8AdGg8ZT"
      },
      "outputs": [],
      "source": [
        "probabilities_of_true_classes = probabilities[ y_train.numpy(), np.arange(0,60000) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aID-8Cuqh3SD",
        "outputId": "35a43e95-1754-4d35-cd73-805778491d08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "probabilities_of_true_classes.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_AYZhtHh50D",
        "outputId": "4f55f3c1-0055-4553-fdea-8a4b58eb2e36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.8809e-20, grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "probabilities_of_true_classes[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvJnbix_jizY",
        "outputId": "e0cc9cf8-b6b7-4157-f98f-13f0fd90b9af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.1617e-12, 8.7327e-14, 5.7248e-18,  ..., 1.2201e-13, 4.4103e-13,\n",
              "        3.2964e-18], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "probabilities[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO-2P2Gmmes0",
        "outputId": "e6eecace-283d-4cb6-def4-902b305be094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Loss per Data Point: 0.7798113226890564\n",
            "Current Loss per Data Point: 0.778701901435852\n",
            "Current Loss per Data Point: 0.7775983214378357\n",
            "Current Loss per Data Point: 0.776500940322876\n",
            "Current Loss per Data Point: 0.7754091620445251\n",
            "Current Loss per Data Point: 0.7743233442306519\n",
            "Current Loss per Data Point: 0.7732434272766113\n",
            "Current Loss per Data Point: 0.7721692323684692\n",
            "Current Loss per Data Point: 0.771100640296936\n",
            "Current Loss per Data Point: 0.7700377702713013\n",
            "Current Loss per Data Point: 0.7689803838729858\n",
            "Current Loss per Data Point: 0.7679286003112793\n",
            "Current Loss per Data Point: 0.7668824195861816\n",
            "Current Loss per Data Point: 0.765841543674469\n",
            "Current Loss per Data Point: 0.7648060917854309\n",
            "Current Loss per Data Point: 0.7637761235237122\n",
            "Current Loss per Data Point: 0.7627512216567993\n",
            "Current Loss per Data Point: 0.7617316246032715\n",
            "Current Loss per Data Point: 0.7607174515724182\n",
            "Current Loss per Data Point: 0.7597082257270813\n",
            "Current Loss per Data Point: 0.7587042450904846\n",
            "Current Loss per Data Point: 0.7577052116394043\n",
            "Current Loss per Data Point: 0.7567113041877747\n",
            "Current Loss per Data Point: 0.7557224035263062\n",
            "Current Loss per Data Point: 0.7547383904457092\n",
            "Current Loss per Data Point: 0.7537594437599182\n",
            "Current Loss per Data Point: 0.7527852654457092\n",
            "Current Loss per Data Point: 0.7518159747123718\n",
            "Current Loss per Data Point: 0.7508512139320374\n",
            "Current Loss per Data Point: 0.7498915195465088\n",
            "Current Loss per Data Point: 0.7489364147186279\n",
            "Current Loss per Data Point: 0.7479860186576843\n",
            "Current Loss per Data Point: 0.7470400929450989\n",
            "Current Loss per Data Point: 0.7460989356040955\n",
            "Current Loss per Data Point: 0.7451622486114502\n",
            "Current Loss per Data Point: 0.7442301511764526\n",
            "Current Loss per Data Point: 0.7433023452758789\n",
            "Current Loss per Data Point: 0.7423792481422424\n",
            "Current Loss per Data Point: 0.7414603233337402\n",
            "Current Loss per Data Point: 0.7405460476875305\n",
            "Current Loss per Data Point: 0.7396359443664551\n",
            "Current Loss per Data Point: 0.7387300729751587\n",
            "Current Loss per Data Point: 0.7378286719322205\n",
            "Current Loss per Data Point: 0.7369312644004822\n",
            "Current Loss per Data Point: 0.7360382676124573\n",
            "Current Loss per Data Point: 0.7351492643356323\n",
            "Current Loss per Data Point: 0.734264612197876\n",
            "Current Loss per Data Point: 0.7333838939666748\n",
            "Current Loss per Data Point: 0.7325073480606079\n",
            "Current Loss per Data Point: 0.7316348552703857\n",
            "Current Loss per Data Point: 0.7307662963867188\n",
            "Current Loss per Data Point: 0.7299016714096069\n",
            "Current Loss per Data Point: 0.7290410995483398\n",
            "Current Loss per Data Point: 0.7281845211982727\n",
            "Current Loss per Data Point: 0.7273316979408264\n",
            "Current Loss per Data Point: 0.7264827489852905\n",
            "Current Loss per Data Point: 0.725637674331665\n",
            "Current Loss per Data Point: 0.7247963547706604\n",
            "Current Loss per Data Point: 0.7239589095115662\n",
            "Current Loss per Data Point: 0.723125159740448\n",
            "Current Loss per Data Point: 0.7222949862480164\n",
            "Current Loss per Data Point: 0.7214688062667847\n",
            "Current Loss per Data Point: 0.72064608335495\n",
            "Current Loss per Data Point: 0.7198270559310913\n",
            "Current Loss per Data Point: 0.7190116047859192\n",
            "Current Loss per Data Point: 0.7181996703147888\n",
            "Current Loss per Data Point: 0.7173914313316345\n",
            "Current Loss per Data Point: 0.716586709022522\n",
            "Current Loss per Data Point: 0.7157853245735168\n",
            "Current Loss per Data Point: 0.7149876952171326\n",
            "Current Loss per Data Point: 0.7141932845115662\n",
            "Current Loss per Data Point: 0.7134023904800415\n",
            "Current Loss per Data Point: 0.7126149535179138\n",
            "Current Loss per Data Point: 0.7118307948112488\n",
            "Current Loss per Data Point: 0.7110501527786255\n",
            "Current Loss per Data Point: 0.7102727293968201\n",
            "Current Loss per Data Point: 0.7094986438751221\n",
            "Current Loss per Data Point: 0.7087277770042419\n",
            "Current Loss per Data Point: 0.7079602479934692\n",
            "Current Loss per Data Point: 0.7071961164474487\n",
            "Current Loss per Data Point: 0.706434965133667\n",
            "Current Loss per Data Point: 0.7056771516799927\n",
            "Current Loss per Data Point: 0.7049224376678467\n",
            "Current Loss per Data Point: 0.7041708827018738\n",
            "Current Loss per Data Point: 0.703422486782074\n",
            "Current Loss per Data Point: 0.7026771903038025\n",
            "Current Loss per Data Point: 0.7019349336624146\n",
            "Current Loss per Data Point: 0.7011957764625549\n",
            "Current Loss per Data Point: 0.7004597783088684\n",
            "Current Loss per Data Point: 0.6997266411781311\n",
            "Current Loss per Data Point: 0.6989966034889221\n",
            "Current Loss per Data Point: 0.6982696056365967\n",
            "Current Loss per Data Point: 0.6975454688072205\n",
            "Current Loss per Data Point: 0.6968243718147278\n",
            "Current Loss per Data Point: 0.6961060762405396\n",
            "Current Loss per Data Point: 0.6953907608985901\n",
            "Current Loss per Data Point: 0.6946782469749451\n",
            "Current Loss per Data Point: 0.6939687132835388\n",
            "Current Loss per Data Point: 0.6932619214057922\n",
            "Current Loss per Data Point: 0.6925581097602844\n"
          ]
        }
      ],
      "source": [
        "# Main training loop\n",
        "\n",
        "alpha = 0.7\n",
        "\n",
        "for epochs in range(100): # 10 updates of gradient descent\n",
        "\n",
        "  # Computing the result of the model\n",
        "  linear_mapping = torch.matmul(A, x_train.t()) + b\n",
        "  logits = linear_mapping.t()\n",
        "  probabilities = torch.nn.Softmax( dim = 1 )( logits )\n",
        "\n",
        "  # Calculating the Loss\n",
        "  # We only care about the probability of the true class, not the others\n",
        "  # - For each image, get probability associated with the true class\n",
        "  # So, we cut out all the unnecessary stuff and only get labels from y_train\n",
        "  probabilities_of_true_classes = probabilities[ np.arange(0,60000), y_train.numpy() ]\n",
        "\n",
        "  # Manually calculating Cross Entropy Loss\n",
        "  # - Mean of tensor of values\n",
        "  loss = torch.mean( -1 * torch.log( probabilities_of_true_classes ) )\n",
        "\n",
        "  print(\"Current Loss per Data Point:\", loss.item())\n",
        "\n",
        "  # Command for differentiation\n",
        "  loss.backward()\n",
        "\n",
        "  # Calculating and using the derivatives (Gradient Descent)\n",
        "  with torch.no_grad(): # Don't bother remembering the calculation since we won't need it for derivatives later.\n",
        "    A -= alpha * A.grad\n",
        "    b -= alpha * b.grad\n",
        "\n",
        "    # Delete gradient so they don't build up over time\n",
        "    A.grad = None\n",
        "    b.grad = None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix:\n",
        "\n",
        "For each image that is actually a 5, what does it get classified as most likely to be?"
      ],
      "metadata": {
        "id": "slEmLfZaLq83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKQqNKScnpny",
        "outputId": "324e4099-5ed9-471c-d037-8c364f95f0f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identification Count Matrix:\n",
            " [[5484    0   52   31   14  169   62   23   65   23]\n",
            " [   0 6286   80   63   11   55   10   23  206    8]\n",
            " [  79  124 4969  160  118   32  147  115  163   51]\n",
            " [  41   22  210 5078    5  351   47   85  191  101]\n",
            " [  21   20   48   23 5027   43   99   61  102  398]\n",
            " [ 146   80   87  268   92 4143  124   56  322  103]\n",
            " [  75   25  115   17   93  126 5360   11   79   17]\n",
            " [  25   50  116   53   92   32    9 5500   32  356]\n",
            " [  45  186  150  259   58  340   69   36 4574  134]\n",
            " [  39   43   34  127  403   87   12  343  113 4748]]\n"
          ]
        }
      ],
      "source": [
        "identification_counts = np.zeros( shape = (10,10), dtype = np.int32 ) # Matrix of all zeros to store the counts of correct vs incorrect classifications\n",
        "linear_mapping = torch.matmul(A, x_train.t()) + b\n",
        "logits = linear_mapping.t()\n",
        "\n",
        "probabilities = torch.nn.Softmax( dim = 1 )( logits )\n",
        "predicted_classes = torch.argmax( probabilities, dim = 1 ) # for probability matrix, get argmax across each row (position of largest predicted probability)\n",
        "\n",
        "for i in range(60000):\n",
        "  actual_class = y_train[i].item() # Actual label of the image\n",
        "  predicted_class = predicted_classes[i].item()\n",
        "\n",
        "  identification_counts[ actual_class, predicted_class ] += 1 # Tally that something of actual_class was most likely (by the model) to be predicted_class\n",
        "\n",
        "\n",
        "print(\"Identification Count Matrix:\\n\", identification_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ex: first row [4299   39  196  119   60  492  343  220  139   16]\n",
        "\n",
        "For images of 0, 4299 images were correctly classified as 0 and 39 were incorrectly classified to be a 1\n",
        "\n",
        "A perfect model would be the identity matrix"
      ],
      "metadata": {
        "id": "UlaQgXJLMc1-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "REhoVm_SMQ_o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}