{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mObgGMdhAcTa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKd-EsgwHSqc",
        "outputId": "b584b22c-d542-41e5-feaf-dca1793d7bbc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 36.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.08MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 7.88MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 12.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dYR1AzmHbL5"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(dataset):\n",
        "    data = (dataset.data / 255.0) - 0.5\n",
        "    flattened_data = data.view(data.shape[0], -1)\n",
        "    targets = dataset.targets\n",
        "    return flattened_data, targets\n",
        "\n",
        "x_train, y_train = preprocess_data(trainset)\n",
        "x_test, y_test = preprocess_data(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJE22eYwHshj",
        "outputId": "2e9729a1-1ca3-4ca0-eb2a-5c5d1ca34564"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([60000, 784])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcFseyGLHtir",
        "outputId": "77e0833f-24b6-4942-ea48-e6628c87732d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPgXfztjHvQL"
      },
      "outputs": [],
      "source": [
        "class MNISTNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer_1 = nn.Linear( in_features = 784, out_features = 1000 ) # Bias = True is the default\n",
        "        self.layer_2 = nn.Linear( in_features = 1000, out_features = 10 )\n",
        "\n",
        "        self.activation_function = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ## Computing the values of the hidden nodes in the first hidden layer\n",
        "        hidden_nodes = self.layer_1(x)\n",
        "        hidden_nodes = self.activation_function( hidden_nodes )\n",
        "        #####################################################################\n",
        "\n",
        "        # Computing the values of the final output layer from the hidden layer\n",
        "        # (But skipping evaluating softmax for now)\n",
        "        logits  = self.layer_2( hidden_nodes )\n",
        "        ######################################################################\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX5T8dkrKWU1"
      },
      "outputs": [],
      "source": [
        "model = MNISTNetwork()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0B5MWGOKY3I"
      },
      "outputs": [],
      "source": [
        "y_pred = model( x_train )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e1XYFq6KioH",
        "outputId": "0862f6b5-f3d5-4bbf-b461-7c51cc6409d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([60000, 10])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAmAPPnzKj_2"
      },
      "outputs": [],
      "source": [
        "model = MNISTNetwork()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7HFhiVnLdIZ"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azB5cjClLfH_"
      },
      "outputs": [],
      "source": [
        "train_dataset = data.TensorDataset(x_train, y_train)\n",
        "\n",
        "batch_size = 1024\n",
        "epochs = 10\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erRTOMXhMY33",
        "outputId": "363ff1f9-53f1-430b-cd1a-3cf0e189e6e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Loss: 0.3774\n",
            "Epoch 2, Average Loss: 0.3674\n",
            "Epoch 3, Average Loss: 0.3586\n",
            "Epoch 4, Average Loss: 0.3517\n",
            "Epoch 5, Average Loss: 0.3494\n",
            "Epoch 6, Average Loss: 0.3409\n",
            "Epoch 7, Average Loss: 0.3370\n",
            "Epoch 8, Average Loss: 0.3321\n",
            "Epoch 9, Average Loss: 0.3290\n",
            "Epoch 10, Average Loss: 0.3246\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        logits = model(x_batch)\n",
        "        loss = loss_function(logits, y_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader) # The number of batches is len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwfxU2EWNHyH",
        "outputId": "698e7b17-7102-446e-9609-194a6ed23f91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Accuracy: 91.23%\n",
            "\n",
            "Confusion Matrix\n",
            "[[ 962    0    3    2    0    3    6    1    3    0]\n",
            " [   0 1105    2    2    0    2    4    1   19    0]\n",
            " [  11   15  896   17   17    2   10   13   46    5]\n",
            " [   4    1   16  925    0   20    2   14   23    5]\n",
            " [   1    6    3    2  920    1   10    2   10   27]\n",
            " [  13    4    3   47   10  748   15    7   39    6]\n",
            " [  18    3    4    1   18   14  893    1    6    0]\n",
            " [   4   19   25    7   11    0    0  930    4   28]\n",
            " [   7   10    5   22    9   21   11    8  875    6]\n",
            " [  13    9    4   12   56    7    0   25   14  869]]\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(x_test)\n",
        "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
        "\n",
        "predicted_classes = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "accuracy = (predicted_classes == y_test).float().mean()\n",
        "\n",
        "print(f\"Overall Accuracy: {accuracy.item() * 100:.2f}%\")\n",
        "\n",
        "print()\n",
        "\n",
        "confusion_matrix = np.zeros((10, 10), dtype=np.int32)\n",
        "\n",
        "for i in range(len(x_test)):\n",
        "    actual_class = y_test[i].item()\n",
        "    predicted_class = predicted_classes[i].item()\n",
        "\n",
        "    confusion_matrix[actual_class, predicted_class] += 1\n",
        "\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_VMWmDZNaCi"
      },
      "outputs": [],
      "source": [
        "class MNISTNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer_1 = nn.Linear( in_features = 784, out_features = 1000 )\n",
        "        self.layer_2 = nn.Linear( in_features = 1000, out_features = 200 )\n",
        "        self.layer_3 = nn.Linear( in_features = 200, out_features = 10 )\n",
        "\n",
        "        self.activation_function = nn.ELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        hidden_nodes = self.layer_1(x)\n",
        "        hidden_nodes = self.activation_function( hidden_nodes )\n",
        "\n",
        "        hidden_nodes = self.layer_2( hidden_nodes )\n",
        "        hidden_nodes = self.activation_function( hidden_nodes )\n",
        "\n",
        "        # Computing the values of the final output layer from the hidden layer\n",
        "        # (But skipping evaluating softmax for now)\n",
        "        logits  = self.layer_3( hidden_nodes )\n",
        "        ######################################################################\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMQTFtzrP67j"
      },
      "outputs": [],
      "source": [
        "model = MNISTNetwork()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnfJISm2P_mY"
      },
      "outputs": [],
      "source": [
        "train_dataset = data.TensorDataset(x_train, y_train)\n",
        "\n",
        "batch_size = 1024\n",
        "epochs = 10\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cjidzmPQCXv",
        "outputId": "40110ede-001a-4c5e-b648-554068d732e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Loss: 1.1218\n",
            "Epoch 2, Average Loss: 0.4965\n",
            "Epoch 3, Average Loss: 0.3793\n",
            "Epoch 4, Average Loss: 0.3412\n",
            "Epoch 5, Average Loss: 0.3330\n",
            "Epoch 6, Average Loss: 0.3059\n",
            "Epoch 7, Average Loss: 0.2994\n",
            "Epoch 8, Average Loss: 0.2815\n",
            "Epoch 9, Average Loss: 0.2716\n",
            "Epoch 10, Average Loss: 0.2575\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        logits = model(x_batch)\n",
        "        loss = loss_function(logits, y_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader) # The number of batches is len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2NtddGTQKEw",
        "outputId": "1d075258-aac7-4e62-9e0b-f39d2d777879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Accuracy: 92.55%\n",
            "\n",
            "Confusion Matrix\n",
            "[[ 963    0    0    1    0    3   11    1    1    0]\n",
            " [   0 1104    2    2    1    3    4    1   17    1]\n",
            " [  12    8  910   10    9    3   21    8   45    6]\n",
            " [   4    1   11  908    0   38    5    4   24   15]\n",
            " [   1    1    2    1  904    0   17    1    8   47]\n",
            " [   9    2    0   21    4  798   19    1   29    9]\n",
            " [   9    3    4    0    5    6  926    1    4    0]\n",
            " [   3   10   23    5    8    1    0  913    3   62]\n",
            " [   6    3    2   15    7   23   14    3  885   16]\n",
            " [  10    8    1    8   22    5    1    4    6  944]]\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(x_test)\n",
        "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
        "\n",
        "predicted_classes = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "accuracy = (predicted_classes == y_test).float().mean()\n",
        "\n",
        "print(f\"Overall Accuracy: {accuracy.item() * 100:.2f}%\")\n",
        "\n",
        "print()\n",
        "\n",
        "confusion_matrix = np.zeros((10, 10), dtype=np.int32)\n",
        "\n",
        "for i in range(len(x_test)):\n",
        "    actual_class = y_test[i].item()\n",
        "    predicted_class = predicted_classes[i].item()\n",
        "\n",
        "    confusion_matrix[actual_class, predicted_class] += 1\n",
        "\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIy6ZA0QSKVD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cs462",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
