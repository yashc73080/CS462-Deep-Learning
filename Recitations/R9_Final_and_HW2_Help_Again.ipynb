{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Goal"
      ],
      "metadata": {
        "id": "a70M8bk1aHu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Homework 2 (HW 2) Help: We will focus on Transfer Learning, especially for Problems 4 and 5.\n",
        "\n",
        "\n",
        "2. Final Project Kick-off: We will help you start the project. The most important \"first step\" is building the \"Basic Logic Bot\". This bot is needed to create your training data."
      ],
      "metadata": {
        "id": "CQO0bCqoaRyh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework2: Transfer Learning"
      ],
      "metadata": {
        "id": "Zrmo02KmaaAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Homework 2, you have Problems 3, 4, and 5.\n",
        "\n",
        "1. Problem 3: You build a CNN to classify CIFAR images. This is your \"baseline\" model.\n",
        "\n",
        "\n",
        "2. Problem 4: You build a model to detect if a CIFAR image is rotated (e.g., by 90 degrees).\n",
        "\n",
        "\n",
        "3. Problem 5: You use the trained model from Problem 4 to help your model for Problem 3"
      ],
      "metadata": {
        "id": "9_1KK2X-afGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why do we do Problem 4 (the rotation task)?**\n",
        "\n",
        "Tthe rotation task itself is not the main goal. The goal is to pre-train your model. By learning to spot rotation, your model learns basic \"visual features\" — like edges, textures, and shapes.\n",
        "\n",
        "Then, in Problem 5, you \"transfer\" these learned features (the model weights) to your new classification task. This is Transfer Learning.\n",
        "\n"
      ],
      "metadata": {
        "id": "8AhMvrdyaxex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You should see that your new model (from Problem 5):**\n",
        "\n",
        "1. Trains faster (needs fewer steps to get a good result).\n",
        "\n",
        "2. May get higher accuracy (it's not starting from zero).\n"
      ],
      "metadata": {
        "id": "l9PqKvH9a_9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The homework also asks you to test two ideas: \"freezing\" vs. \"fine-tuning\".**\n",
        "\n",
        "\n",
        "1. Freezing: You \"lock\" the transferred layers and only train the final, new classification layer.\n",
        "\n",
        "\n",
        "2. Fine-Tuning: You \"unlock\" all layers and let them all train, but usually with a smaller learning rate."
      ],
      "metadata": {
        "id": "VyaYcqRfbHYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (Note: You must define your own model structure as required by the HW)\n",
        "\n",
        "# Problem 4: Pre-training\n",
        "\n",
        "# 1. Prepare the \"rotation\" dataset\n",
        "def create_rotation_dataset(cifar_images):\n",
        "    # Loop\n",
        "        # Randomly choose 0 or 90 degrees\n",
        "        # Rotate the image\n",
        "        # Create a (rotated_image, label) pair.\n",
        "        # For example: 0 = upright, 1 = rotated 90 deg\n",
        "    # return (rotated_images, rotation_labels)\n",
        "    pass\n",
        "\n",
        "# 2. Build the \"rotation detection\" model\n",
        "# Note: The last layer should be for binary classification (0 or 1)\n",
        "rotation_model = YourModelArchitecture(output_units=2)\n",
        "\n",
        "# 3. Train the model\n",
        "# (Use your training loop)\n",
        "rotation_model.train(rotated_images, rotation_labels)\n",
        "\n",
        "# 4. Save the pre-trained weights\n",
        "# We only care about the \"feature\" layers (like CNNs), not the final output layer.\n",
        "rotation_model.save_feature_layer_weights('pretrained_weights.pth')\n"
      ],
      "metadata": {
        "id": "rL8KoJrMbNUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 5: Transfer Learning\n",
        "\n",
        "# 1. Prepare the \"classification\" dataset\n",
        "# (This is the original CIFAR dataset)\n",
        "(cifar_images, cifar_labels) = load_cifar_data()\n",
        "\n",
        "# 2. Build the \"classification\" model\n",
        "# This model's feature layers MUST have the same architecture as the rotation_model\n",
        "classification_model = YourModelArchitecture(output_units=10) # 10 classes\n",
        "\n",
        "# 3. Load the pre-trained weights\n",
        "classification_model.load_feature_layer_weights('pretrained_weights.pth')\n",
        "\n",
        "# 4. Experiment A: Freeze layers\n",
        "# Loop through all feature layers (but NOT the final output layer)\n",
        "for layer in classification_model.feature_layers:\n",
        "    layer.requires_grad = False # This \"freezes\" the layer\n",
        "\n",
        "# 5. Train Experiment A\n",
        "print(\"Training with FROZEN layers...\")\n",
        "# (Use your training loop)\n",
        "classification_model.train(cifar_images, cifar_labels)\n",
        "# (Record your loss and accuracy)\n",
        "\n",
        "# 6. Experiment B: Fine-tuning\n",
        "# You must reload the model or \"unfreeze\" the layers\n",
        "for layer in classification_model.feature_layers:\n",
        "    layer.requires_grad = True # This \"unfreezes\" the layer\n",
        "\n",
        "print(\"Training with ALL layers (Fine-tuning)...\")\n",
        "# (Use your training loop, maybe with a smaller learning rate)\n",
        "classification_model.train(cifar_images, cifar_labels)\n",
        "# (Record your loss and accuracy)\n",
        "\n",
        "# 7. Compare\n",
        "# Compare Problem 3 (from scratch) vs. Experiment A (freeze) vs. Experiment B (fine-tuning)\n",
        "# Look at:\n",
        "# - Final test loss / accuracy\n",
        "# - Training time / steps to get that result"
      ],
      "metadata": {
        "id": "0gEghx8vbSWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Project"
      ],
      "metadata": {
        "id": "FYedTQtvbVqu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is November, and you should complete the first step:\n",
        "\n",
        "1. Code the Minesweeper game environment.\n",
        "\n",
        "2. Code the \"basic logic bot\"."
      ],
      "metadata": {
        "id": "mV4Lsl7bbZZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why is this Bot so important?\n",
        "\n",
        "\n",
        "For Task 1 (Supervised Learning): You need data to train your model. This bot can play many games. You can use it to generate (board_state, mine_locations) data pairs.\n",
        "\n",
        "\n",
        "\n",
        "For Task 2 (Actor-Critic): This bot is your \"initial actor\". Your Critic network can start by learning to predict this bot's performance."
      ],
      "metadata": {
        "id": "rKbNoNltblei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This pseudocode follows the logic from the project PDF"
      ],
      "metadata": {
        "id": "6A6hTrssbqSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogicBot:\n",
        "    def __init__(self, game_environment):\n",
        "        self.game = game_environment\n",
        "        self.H, self.W = game.shape\n",
        "\n",
        "        # Initialize sets [cite: 15]\n",
        "        self.cells_remaining = set((r, c) for r in range(self.H) for c in range(self.W))\n",
        "        self.inferred_safe = set()\n",
        "        self.inferred_mine = set()\n",
        "\n",
        "        # Store revealed clues: { (r, c) : clue_number } [cite: 16]\n",
        "        self.clue_numbers = {}\n",
        "        self.game_over = False\n",
        "\n",
        "    def play_game(self):\n",
        "        # Loop until game ends [cite: 17]\n",
        "        while not self.game_over:\n",
        "\n",
        "            # 1. Choose a cell to open [cite: 18]\n",
        "            if self.inferred_safe:\n",
        "                cell_to_open = self.inferred_safe.pop()\n",
        "            else:\n",
        "                # If no safe cells, pick a random cell from \"remaining\" [cite: 18]\n",
        "                # (Make sure not to pick one we already think is a mine)\n",
        "                available_cells = self.cells_remaining - self.inferred_mine\n",
        "                if not available_cells:\n",
        "                    break # No more cells to open\n",
        "                cell_to_open = random.choice(list(available_cells))\n",
        "\n",
        "            # 2. Open the cell [cite: 19]\n",
        "            (r, c) = cell_to_open\n",
        "            clue = self.game.open(r, c) # Assume game.open() returns -1 for a mine\n",
        "\n",
        "            self.cells_remaining.discard((r, c))\n",
        "\n",
        "            if clue == -1: # Hit a mine [cite: 19]\n",
        "                self.game_over = True\n",
        "                # (record results)\n",
        "                break\n",
        "            else:\n",
        "                # 3. Update clues [cite: 20]\n",
        "                self.clue_numbers[(r, c)] = clue\n",
        "\n",
        "                # 4. Run the inference loop [cite: 24]\n",
        "                self.run_inference_loop()\n",
        "\n",
        "        # (Return game results)\n",
        "        pass\n",
        "\n",
        "    def run_inference_loop(self):\n",
        "        # Keep looping until no new inferences are made [cite: 24]\n",
        "        while True:\n",
        "            new_inferences_made = False\n",
        "\n",
        "            # For each cell with a revealed clue [cite: 21]\n",
        "            for (r, c), clue_value in self.clue_numbers.items():\n",
        "\n",
        "                # (You need a helper function get_neighbors(r, c))\n",
        "                all_neighbors = self.get_neighbors(r, c)\n",
        "\n",
        "                # Count neighbors\n",
        "                unrevealed_neighbors = []\n",
        "                num_inferred_mines_around = 0\n",
        "                num_inferred_safe_around = 0\n",
        "                num_revealed_safe_around = 0\n",
        "\n",
        "                for nr, nc in all_neighbors:\n",
        "                    if (nr, nc) in self.inferred_mine:\n",
        "                        num_inferred_mines_around += 1\n",
        "                    elif (nr, nc) in self.inferred_safe:\n",
        "                        num_inferred_safe_around += 1\n",
        "                    elif (nr, nc) in self.clue_numbers:\n",
        "                        # This cell is already open, so it's safe\n",
        "                        num_revealed_safe_around += 1\n",
        "                    elif (nr, nc) in self.cells_remaining:\n",
        "                        # This is an unknown, un-inferred neighbor\n",
        "                        unrevealed_neighbors.append((nr, nc))\n",
        "\n",
        "                num_unrevealed = len(unrevealed_neighbors)\n",
        "                if num_unrevealed == 0:\n",
        "                    continue\n",
        "\n",
        "                # Core Logic 1: Mark Mines\n",
        "                # If (clue_value) - (# known mines) == (# unrevealed neighbors)\n",
        "                # Then all unrevealed neighbors MUST be mines.\n",
        "                if (clue_value - num_inferred_mines_around) == num_unrevealed:\n",
        "                    for (nr, nc) in unrevealed_neighbors:\n",
        "                        if (nr, nc) not in self.inferred_mine:\n",
        "                            self.inferred_mine.add((nr, nc))\n",
        "                            self.cells_remaining.discard((nr, nc)) # Remove from \"remaining\" [cite: 22]\n",
        "                            new_inferences_made = True\n",
        "\n",
        "\n",
        "                # Core Logic 2: Mark Safe\n",
        "                # (total # neighbors) - (clue_value) == total # of safe neighbors\n",
        "                # (known safe neighbors) = (inferred safe) + (revealed safe)\n",
        "\n",
        "                total_neighbors_count = len(all_neighbors)\n",
        "                total_safe_neighbors_count = total_neighbors_count - clue_value\n",
        "                known_safe_neighbors_count = num_inferred_safe_around + num_revealed_safe_around\n",
        "\n",
        "                # If (total safe neighbors needed) - (known safe neighbors) == (# unrevealed neighbors)\n",
        "                # Then all unrevealed neighbors MUST be safe.\n",
        "                if (total_safe_neighbors_count - known_safe_neighbors_count) == num_unrevealed:\n",
        "                    for (nr, nc) in unrevealed_neighbors:\n",
        "                        if (nr, nc) not in self.inferred_safe:\n",
        "                            self.inferred_safe.add((nr, nc))\n",
        "                            # (Do NOT remove from cells_remaining.\n",
        "                            #  They will be picked by the main loop.)\n",
        "                            new_inferences_made = True\n",
        "\n",
        "            # If this whole loop made no new inferences, we are done.\n",
        "            if not new_inferences_made:\n",
        "                break\n",
        "\n",
        "    def get_neighbors(self, r, c):\n",
        "        # (Helper function: returns valid (r, c) coords for all 8 neighbors)\n",
        "        neighbors = []\n",
        "        for dr in [-1, 0, 1]:\n",
        "            for dc in [-1, 0, 1]:\n",
        "                if dr == 0 and dc == 0:\n",
        "                    continue\n",
        "                nr, nc = r + dr, c + dc\n",
        "                if 0 <= nr < self.H and 0 <= nc < self.W:\n",
        "                    neighbors.append((nr, nc))\n",
        "        return neighbors"
      ],
      "metadata": {
        "id": "kFNVT3JrbwNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is just an idea, and you can also follow your own way, there is not the only one solution. If it's reasonable, it's right."
      ],
      "metadata": {
        "id": "xz3nzAzgb0xa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2\n",
        "\n",
        "A naive training scheme:\n",
        "\n",
        "1.   Use logic bot to play the game, obtaining datset `D_1`.\n",
        "2.   train `Φ_1(s,a)` using `D_1`.\n",
        "3.   Use `argmax(Φ_1(s,a))` to play the game, obtaining datset `D_2`.\n",
        "4.   train `Φ_2(s,a)` using `D_2`.\n",
        "\n",
        "...(repeat until the performance does not improve)\n"
      ],
      "metadata": {
        "id": "iiFGH29W0SII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Note\n",
        "\n",
        "You might not even get bad results from very simple methods. But the other point to this project is to **demonstrate what you've learned** in the course."
      ],
      "metadata": {
        "id": "Z0fyM9032ZWv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1MwtWWmucBg6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}