{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a124293e",
   "metadata": {},
   "source": [
    "Draw on everything we've discussed to build and train a model to get the best performance on CIFAR that you can. Tentatively due on the 10th. Ideally you can set this up to run fairly easily using the code that you've developed so far, and can let that churn while you focus on your final project.\n",
    "\n",
    "(Somewhat open ended question - there is no 'right' answer here, but I am looking for some amount of thoroughness/breadth of your approach and discussion of your approach. One thing that I'll note here, it might be worth thinking about how you could experiment with different models to find a good one before launching a 'full' training run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27986e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f6f2eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83169a0",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9670996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 (32x32 RGB)\n",
    "normalize = transforms.Normalize( mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010], )\n",
    "transform = transforms.Compose([ transforms.Resize((224,224)), transforms.ToTensor(), normalize])\n",
    "\n",
    "cifar_train_ds = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "cifar_test_ds  = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "cifar_train_loader = DataLoader(cifar_train_ds, batch_size=256, shuffle=True, num_workers=0, pin_memory=True)\n",
    "cifar_test_loader  = DataLoader(cifar_test_ds,  batch_size=512, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d898061c",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bfe443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetwork(nn.Module):\n",
    "    def __init__(self, input_size=(3, 32, 32), num_classes=10, device='cpu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        conv_layers = []\n",
    "        conv_layers.extend([\n",
    "            nn.Conv2d(input_size[0], 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        ])\n",
    "        self.conv_layers = nn.Sequential(*conv_layers)\n",
    "\n",
    "        # Get flattened size with dummy tensor\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, *input_size)\n",
    "            dummy_out = self.conv_layers(dummy)\n",
    "            flattened_dim = dummy_out.view(1, -1).size(1)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        fc_layers = []\n",
    "        fc_layers.extend([\n",
    "            nn.Linear(flattened_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        ])\n",
    "        self.fc_layers = nn.Sequential(*fc_layers)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cefcc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs=10, lr=0.001, plot=False, device='cpu'):\n",
    "    model.to(device)\n",
    "    train_losses, test_losses = [], []\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        test_running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_test_loss = test_running_loss / len(test_loader.dataset)\n",
    "        test_losses.append(epoch_test_loss)\n",
    "\n",
    "        if epoch % 1 == 0 or epoch == num_epochs - 1:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Test Loss: {epoch_test_loss:.4f}\")\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "        plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Test Loss over Epochs')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return model, train_losses, test_losses\n",
    "\n",
    "def test_model(model, test_loader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a869d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = ConvNetwork(input_size=(3, 32, 32), device=device)\n",
    "cnn, train_losses, test_losses = train_model(cnn, cifar_train_loader, cifar_test_loader, num_epochs=20, lr=0.001, plot=True, device=device)\n",
    "final_test_accuracy = test_model(cnn, cifar_test_loader, device=device)\n",
    "\n",
    "print(f\"Final Test Accuracy: {final_test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a4355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
